{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib nbagg\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "\n",
    "from IPython.display import display,HTML,clear_output\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from math import pi as PI\n",
    "\n",
    "mpl.use('nbagg')\n",
    "\n",
    "from matplotlib import animation\n",
    "mpl.rc('animation', html='html5') #display animated plots inline\n",
    "\n",
    "from robmob.robot import Robot\n",
    "from robmob.sensors import KinectRGBSensor\n",
    "from robmob.visualization import Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ip_robot = '192.168.0.109'\n",
    "robot = Robot(ip_robot)\n",
    "robot.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kinect = KinectRGBSensor()\n",
    "robot.add_sensor(kinect)\n",
    "img1 = cv2.imread('qr.jpg',0)          # queryImage\n",
    "# print(\"type of img1: \", type(img1))\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inlines(image):\n",
    "    frame = np.array(image)\n",
    "#     print(frame)\n",
    "    \n",
    "    MIN_MATCH_COUNT = 10\n",
    "\n",
    "    kp2, des2 = sift.detectAndCompute(frame,None)\n",
    "    \n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good) > MIN_MATCH_COUNT:\n",
    "        return len(good)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scan_inlines(angle, speed):\n",
    "    max_inlines = False\n",
    "    inlines = 0\n",
    "    val=[]\n",
    "    while not max_inlines:\n",
    "        robot.angular_movement(angle, speed)\n",
    "#         clear_output(wait=True)\n",
    "        time.sleep(1)\n",
    "        image = kinect.peek_data()\n",
    "#         display(image)\n",
    "        new_inlines = get_inlines(image)\n",
    "        print(\"new_ilneles \" , new_inlines, \"inlines: \", inlines)\n",
    "        time.sleep(1)\n",
    "        kinect.buffer.clear()\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if inlines <= new_inlines:\n",
    "            inlines = new_inlines\n",
    "            print(\"not max_inlines\")\n",
    "        else:\n",
    "            max_inlines = False\n",
    "            print(\"yes\")\n",
    "            return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_z():\n",
    "    time.sleep(1)\n",
    "    image = kinect.peek_data()\n",
    "    time.sleep(1)\n",
    "    frame = np.array(image)\n",
    "    kinect.buffer.clear()\n",
    "    clear_output(wait=True)\n",
    "#     print(frame)\n",
    "    \n",
    "    MIN_MATCH_COUNT = 10\n",
    "\n",
    "    kp2, des2 = sift.detectAndCompute(frame,None)\n",
    "    \n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good) < MIN_MATCH_COUNT:\n",
    "        return 0\n",
    "    \n",
    "    for dmatch in good:\n",
    "        print(dmatch)\n",
    "#         point1 = kp1[dmatch[0].queryIdx].pt\n",
    "        point2 = kp2[dmatch[0].queryIdx].pt\n",
    "#         print('Point1: ',point1)\n",
    "#         print('Point2: ',point2)\n",
    "    print('---------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DMatch 0x7f723a692150>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'cv2.DMatch' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-56a5ded206b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscan_inlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPI\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscan_inlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mPI\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfind_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-22136587d821>\u001b[0m in \u001b[0;36mfind_z\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#         point1 = kp1[dmatch[0].queryIdx].pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpoint2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkp2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueryIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m#         print('Point1: ',point1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#         print('Point2: ',point2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'cv2.DMatch' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# liste = scan_inlines()\n",
    "# rotate_to_max(liste)\n",
    "scan_inlines(PI/8,1)\n",
    "scan_inlines(-PI/16,0.5)\n",
    "find_z()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kinect.buffer.clear()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
