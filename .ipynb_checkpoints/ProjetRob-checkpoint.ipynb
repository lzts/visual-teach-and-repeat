{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib nbagg\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "\n",
    "from IPython.display import display,HTML,clear_output\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from math import pi as PI\n",
    "\n",
    "mpl.use('nbagg')\n",
    "\n",
    "from matplotlib import animation\n",
    "mpl.rc('animation', html='html5') #display animated plots inline\n",
    "\n",
    "from robmob.robot import Robot\n",
    "from robmob.sensors import KinectRGBSensor\n",
    "from robmob.visualization import Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ip_robot = '192.168.0.109'\n",
    "robot = Robot(ip_robot)\n",
    "robot.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kinect = KinectRGBSensor()\n",
    "robot.add_sensor(kinect)\n",
    "img1 = cv2.imread('qr.jpg',0)          # queryImage\n",
    "# print(\"type of img1: \", type(img1))\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_inlines(image):\n",
    "    frame = np.array(image)\n",
    "#     print(frame)\n",
    "    \n",
    "    MIN_MATCH_COUNT = 10\n",
    "\n",
    "    kp2, des2 = sift.detectAndCompute(frame,None)\n",
    "    \n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good) > MIN_MATCH_COUNT:\n",
    "        return len(good)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scan_inlines(angle, speed):\n",
    "    max_inlines = False\n",
    "    inlines = 0\n",
    "    val=[]\n",
    "    while not max_inlines:\n",
    "        robot.angular_movement(angle, speed)\n",
    "#         clear_output(wait=True)\n",
    "        time.sleep(1)\n",
    "        image = kinect.peek_data()\n",
    "#         display(image)\n",
    "        new_inlines = get_inlines(image)\n",
    "        print(\"new_ilneles \" , new_inlines, \"inlines: \", inlines)\n",
    "        time.sleep(1)\n",
    "        kinect.buffer.clear()\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if inlines <= new_inlines:\n",
    "            inlines = new_inlines\n",
    "            print(\"not max_inlines\")\n",
    "        else:\n",
    "            max_inlines = False\n",
    "            print(\"yes\")\n",
    "            return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_z():\n",
    "    time.sleep(1)\n",
    "    image = kinect.peek_data()\n",
    "    time.sleep(1)\n",
    "    frame = np.array(image)\n",
    "    kinect.buffer.clear()\n",
    "    clear_output(wait=True)\n",
    "#     print(frame)\n",
    "    \n",
    "    MIN_MATCH_COUNT = 10\n",
    "\n",
    "    kp2, des2 = sift.detectAndCompute(frame,None)\n",
    "    \n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good) < MIN_MATCH_COUNT:\n",
    "        return 0\n",
    "    \n",
    "    for dmatch in good:\n",
    "        print(dmatch)\n",
    "#         point1 = kp1[dmatch[0].queryIdx].pt\n",
    "        point2 = kp2[dmatch[0].queryIdx].pt\n",
    "#         print('Point1: ',point1)\n",
    "#         print('Point2: ',point2)\n",
    "    print('---------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Le buffeur du capteur est vide",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/vabic/visual-teach-and-repeat/robmob/sensors.py\u001b[0m in \u001b[0;36mpeek_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: deque index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-56a5ded206b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# liste = scan_inlines()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# rotate_to_max(liste)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscan_inlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPI\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mscan_inlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mPI\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfind_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-74106bda499a>\u001b[0m in \u001b[0;36mscan_inlines\u001b[0;34m(angle, speed)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mrobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangular_movement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#         clear_output(wait=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkinect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeek_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#         display(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnew_inlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_inlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vabic/visual-teach-and-repeat/robmob/sensors.py\u001b[0m in \u001b[0;36mpeek_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Le buffeur du capteur est vide'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;31m# print('Le buffeur du capteur est vide')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Le buffeur du capteur est vide"
     ]
    }
   ],
   "source": [
    "# liste = scan_inlines()\n",
    "# rotate_to_max(liste)\n",
    "scan_inlines(PI/8,1)\n",
    "scan_inlines(-PI/16,0.5)\n",
    "find_z()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kinect.buffer.clear()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
